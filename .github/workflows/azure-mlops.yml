name: mlops-automation

on:
  workflow_dispatch:
  push:
    branches: [ main ]

env:
  GROUP: azure-ai
  WORKSPACE: tomasrojka-ml
  LOCATION: westeurope

jobs:
  # ------------------------------------------
  # 1) Run Azure ML pipeline (compute + env + components + job)
  # ------------------------------------------
  azure-pipeline:
    runs-on: ubuntu-24.04

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      # OPTIONAL – keep this if you still want the run ID in logs
      - name: Set pipeline run id
        run: echo "GITHUB_RUN_ID=${{ github.run_id }}" >> $GITHUB_ENV

      - name: Azure – Create compute + envs + components + pipeline run
        id: submit_job
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: 2.64.0
          inlineScript: |
            az extension add --name ml -y
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION

            # 1. Compute instance (safe if it exists already)
            az ml compute create --file environment/compute.yaml || true

            # 2. Environments  (safe if already registered)
            for ENV in preprocessing training; do
              az ml environment create --file environment/${ENV}.yaml || true
            done

            # 3. Components
            for COMP in \
              components/dataprep/dataprep.yaml \
              components/dataprep/traintestsplit.yaml \
              components/training/training.yaml
            do
              az ml component create --file $COMP
            done

            # 4. Run pipeline
            JOB_NAME=$(az ml job create \
              --file pipelines/animals-classification.yaml \
              --query name -o tsv)

            echo "job_name=$JOB_NAME" >> $GITHUB_OUTPUT

            # 5. Cleanup – stop compute
            az ml compute stop --name cli-created-machine || true

    outputs:
      job_name: ${{ steps.submit_job.outputs.job_name }}

  # ------------------------------------------
  # 2) DOWNLOAD – grab latest registered model + upload inference code
  # ------------------------------------------
  download:
    needs: azure-pipeline
    runs-on: ubuntu-24.04

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Azure – Download latest model
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: 2.64.0
        # ⬇⬇ This is exactly what the assignment is asking for in the “Download AI Model” question
          inlineScript: |
            az extension add --name ml -y
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION

            # Get latest version of your registered model
            VERSION=$(az ml model list -n animal-classification \
              --query "[0].version" -o tsv)

            echo "Latest model version: $VERSION"

            # Download into inference/model (Docker context later)
            az ml model download \
              --name animal-classification \
              --version $VERSION \
              --download-path inference/model \
              --overwrite

      # This is the upload-artifact step the Notion file talks about
      - name: Docker – Upload API code from inference
        uses: actions/upload-artifact@v4
        with:
          name: docker-config
          path: inference

  # ------------------------------------------
  # 3) DEPLOY – build Docker image + push + (optional) apply k8s manifests
  # ------------------------------------------
  deploy:
    needs: download
    runs-on: ubuntu-24.04   # GitHub-hosted is fine for build+push

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # bring back inference/ (API code + downloaded model)
      - name: Download API + model artifact
        uses: actions/download-artifact@v4
        with:
          name: docker-config
          path: inference

      # create Docker tags/labels
      - name: Docker – Gather tags
        id: docker-meta-data
        uses: docker/metadata-action@v5
        with:
          images: |
            docker.io/tomasrojka/animals-api
          tags: |
            type=ref,event=branch
            type=sha
            type=raw,value=latest

      # login to Docker Hub
      - name: Docker – Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      # build + push image using inference/ as build context
      - name: Docker – Build and push
        uses: docker/build-push-action@v6
        with:
          context: ./inference
          push: true
          tags: ${{ steps.docker-meta-data.outputs.tags }}
          labels: ${{ steps.docker-meta-data.outputs.labels }}
